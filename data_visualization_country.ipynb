{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd052ff49cc06b74dac6aaef5d7daa0fee3232336051e9da08aa968db01a51e2d0e",
   "display_name": "Python 3.9.4 64-bit ('as-analysis-4ZNE6qS_': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "RATIO = 0.7"
   ]
  },
  {
   "source": [
    "## build dataframe with graph analysis data\n",
    "- only take ASs with minimum LCC coverage\n",
    "- remove columns containing distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.read_csv(\"analysis_2020_08/analysis.tsv\", delimiter=\"\\t\", index_col=0).dropna(how=\"all\", subset=[\"avg_coreness\", \"graph_coreness\", \"core_order\", \"density_lcc\", \"assortativity_lcc\", \"transitivity_lcc\", \"avg_shortest_path_len\", \"approx_avg_shortest_path_len\"]).drop(columns=[\"ri_pp_ifs_dis\", \"ri_tot_neighs_dis\", \"dis_leaf1_aggr_type\", \"dis_leaf_aggr_leaf1_num\", \"re_pp_ifs_dis\", \"re_tot_neighs_dis\"])"
   ]
  },
  {
   "source": [
    "## Classify ASs by country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n\\ngeo_dict:\\n\\n{'11814': 'NA',\\n '31655': 'EU',\\n '9381': 'AS',\\n '13489': 'SA',\\n ...}\\n\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "with open(\"stats/geo_country_data.json\", \"r\", encoding=\"utf8\") as file_in:\n",
    "    geo_all_dict = json.load(file_in)\n",
    "geo_dict = dict()\n",
    "country_count = defaultdict(lambda: 0)\n",
    "for as_num, data in geo_all_dict.items():\n",
    "    for country, nodes in data.items():\n",
    "        if country == \"tot_nodes_count\":\n",
    "            tot = nodes\n",
    "        else:\n",
    "            if nodes >= RATIO * tot:\n",
    "                geo_dict[as_num] = country\n",
    "                country_count[country] += 1\n",
    "    if as_num not in geo_dict:\n",
    "        # international\n",
    "        geo_dict[as_num] = \"INTERNATIONAL\"\n",
    "        country_count[\"INTERNATIONAL\"] += 1\n",
    "\n",
    "'''\n",
    "geo_dict:\n",
    "\n",
    "{'11814': 'NA',\n",
    " '31655': 'EU',\n",
    " '9381': 'AS',\n",
    " '13489': 'SA',\n",
    " ...}\n",
    "'''"
   ]
  },
  {
   "source": [
    "## Average stats for each country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        ds_nodes       ds_links  largest_cc_size  largest_cc_coverage  \\\n",
       "CA  13543.800000   26692.680000     18988.400000             0.968280   \n",
       "GB  48053.161290   70596.129032     65250.258065             0.977160   \n",
       "HK  13003.400000   39933.400000     26466.400000             0.967066   \n",
       "US  33781.566308  124988.211470     50528.609319             0.981056   \n",
       "SG  11818.777778   20592.222222     19255.111111             0.987908   \n",
       "..           ...            ...              ...                  ...   \n",
       "MO   8578.000000   23698.000000     12001.000000             0.929445   \n",
       "IM   2959.000000    3553.000000      3288.000000             0.985907   \n",
       "SM   1169.000000    2288.000000      2183.000000             0.926570   \n",
       "AX   1418.000000    1927.000000      1718.000000             0.992490   \n",
       "CV   1873.000000    3663.000000      3643.000000             0.990753   \n",
       "\n",
       "      as_routers  non_as_routers         leaf1        leaf2     default  \\\n",
       "CA  13543.800000     5947.000000   9440.400000   358.120000   73.560000   \n",
       "GB  48053.161290    18327.483871  30486.967742   782.516129  156.064516   \n",
       "HK  13003.400000    14476.100000   3308.800000   174.700000  152.200000   \n",
       "US  33781.566308    17763.616487  25439.279570  1065.831541  200.222222   \n",
       "SG  11818.777778     7913.111111   3558.333333   565.444444  210.777778   \n",
       "..           ...             ...           ...          ...         ...   \n",
       "MO   8578.000000     4334.000000   6992.000000   216.000000   27.000000   \n",
       "IM   2959.000000      376.000000   2879.000000    27.000000    7.000000   \n",
       "SM   1169.000000     1187.000000     27.000000     0.000000    0.000000   \n",
       "AX   1418.000000      313.000000   1324.000000    26.000000   28.000000   \n",
       "CV   1873.000000     1804.000000     54.000000     3.000000    0.000000   \n",
       "\n",
       "          border  ...  re_tot_tot_neighs  avg_coreness  graph_coreness  \\\n",
       "CA   3671.720000  ...       12192.600000      1.162122        6.800000   \n",
       "GB  16627.612903  ...       35871.387097      1.183927        8.000000   \n",
       "HK   9367.700000  ...       30674.200000      1.327917       12.600000   \n",
       "US   7076.232975  ...       70068.476703      1.255765        9.193548   \n",
       "SG   7484.222222  ...       15351.444444      1.085044        6.333333   \n",
       "..           ...  ...                ...           ...             ...   \n",
       "MO   1343.000000  ...       11503.000000      1.666028       20.000000   \n",
       "IM     46.000000  ...         530.000000      1.063869        6.000000   \n",
       "SM   1142.000000  ...        2259.000000      1.016949        2.000000   \n",
       "AX     40.000000  ...         455.000000      1.120489        5.000000   \n",
       "CV   1816.000000  ...        3605.000000      1.003843        2.000000   \n",
       "\n",
       "    core_order  density_lcc  assortativity_lcc  transitivity_lcc  \\\n",
       "CA   34.880000     0.000736          -0.388792          0.005351   \n",
       "GB   17.870968     0.000750          -0.456396          0.011898   \n",
       "HK  146.300000     0.000584          -0.438198          0.007695   \n",
       "US   86.842294     0.000715          -0.492724          0.010836   \n",
       "SG   20.888889     0.000686          -0.476463          0.002107   \n",
       "..         ...          ...                ...               ...   \n",
       "MO   35.000000     0.000271          -0.536726          0.018431   \n",
       "IM   13.000000     0.000642          -0.734882          0.001026   \n",
       "SM   37.000000     0.000921          -0.339166          0.000000   \n",
       "AX   21.000000     0.001285          -0.501270          0.001380   \n",
       "CV   14.000000     0.000550          -0.318008          0.000002   \n",
       "\n",
       "    approx_avg_shortest_path_len  time_to_analyze  count  \n",
       "CA                      4.061947      1366.114253     25  \n",
       "GB                      4.430111      4919.532139     31  \n",
       "HK                      4.200105      1812.862610     10  \n",
       "US                      4.510466      7816.092534    279  \n",
       "SG                      3.640661      1954.083002      9  \n",
       "..                           ...              ...    ...  \n",
       "MO                      4.093326       574.182598      1  \n",
       "IM                      4.291894        72.743141      1  \n",
       "SM                      2.996304        33.599915      1  \n",
       "AX                      3.384614        21.820762      1  \n",
       "CV                      3.149997        93.046447      1  \n",
       "\n",
       "[108 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds_nodes</th>\n      <th>ds_links</th>\n      <th>largest_cc_size</th>\n      <th>largest_cc_coverage</th>\n      <th>as_routers</th>\n      <th>non_as_routers</th>\n      <th>leaf1</th>\n      <th>leaf2</th>\n      <th>default</th>\n      <th>border</th>\n      <th>...</th>\n      <th>re_tot_tot_neighs</th>\n      <th>avg_coreness</th>\n      <th>graph_coreness</th>\n      <th>core_order</th>\n      <th>density_lcc</th>\n      <th>assortativity_lcc</th>\n      <th>transitivity_lcc</th>\n      <th>approx_avg_shortest_path_len</th>\n      <th>time_to_analyze</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CA</th>\n      <td>13543.800000</td>\n      <td>26692.680000</td>\n      <td>18988.400000</td>\n      <td>0.968280</td>\n      <td>13543.800000</td>\n      <td>5947.000000</td>\n      <td>9440.400000</td>\n      <td>358.120000</td>\n      <td>73.560000</td>\n      <td>3671.720000</td>\n      <td>...</td>\n      <td>12192.600000</td>\n      <td>1.162122</td>\n      <td>6.800000</td>\n      <td>34.880000</td>\n      <td>0.000736</td>\n      <td>-0.388792</td>\n      <td>0.005351</td>\n      <td>4.061947</td>\n      <td>1366.114253</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>GB</th>\n      <td>48053.161290</td>\n      <td>70596.129032</td>\n      <td>65250.258065</td>\n      <td>0.977160</td>\n      <td>48053.161290</td>\n      <td>18327.483871</td>\n      <td>30486.967742</td>\n      <td>782.516129</td>\n      <td>156.064516</td>\n      <td>16627.612903</td>\n      <td>...</td>\n      <td>35871.387097</td>\n      <td>1.183927</td>\n      <td>8.000000</td>\n      <td>17.870968</td>\n      <td>0.000750</td>\n      <td>-0.456396</td>\n      <td>0.011898</td>\n      <td>4.430111</td>\n      <td>4919.532139</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>HK</th>\n      <td>13003.400000</td>\n      <td>39933.400000</td>\n      <td>26466.400000</td>\n      <td>0.967066</td>\n      <td>13003.400000</td>\n      <td>14476.100000</td>\n      <td>3308.800000</td>\n      <td>174.700000</td>\n      <td>152.200000</td>\n      <td>9367.700000</td>\n      <td>...</td>\n      <td>30674.200000</td>\n      <td>1.327917</td>\n      <td>12.600000</td>\n      <td>146.300000</td>\n      <td>0.000584</td>\n      <td>-0.438198</td>\n      <td>0.007695</td>\n      <td>4.200105</td>\n      <td>1812.862610</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>33781.566308</td>\n      <td>124988.211470</td>\n      <td>50528.609319</td>\n      <td>0.981056</td>\n      <td>33781.566308</td>\n      <td>17763.616487</td>\n      <td>25439.279570</td>\n      <td>1065.831541</td>\n      <td>200.222222</td>\n      <td>7076.232975</td>\n      <td>...</td>\n      <td>70068.476703</td>\n      <td>1.255765</td>\n      <td>9.193548</td>\n      <td>86.842294</td>\n      <td>0.000715</td>\n      <td>-0.492724</td>\n      <td>0.010836</td>\n      <td>4.510466</td>\n      <td>7816.092534</td>\n      <td>279</td>\n    </tr>\n    <tr>\n      <th>SG</th>\n      <td>11818.777778</td>\n      <td>20592.222222</td>\n      <td>19255.111111</td>\n      <td>0.987908</td>\n      <td>11818.777778</td>\n      <td>7913.111111</td>\n      <td>3558.333333</td>\n      <td>565.444444</td>\n      <td>210.777778</td>\n      <td>7484.222222</td>\n      <td>...</td>\n      <td>15351.444444</td>\n      <td>1.085044</td>\n      <td>6.333333</td>\n      <td>20.888889</td>\n      <td>0.000686</td>\n      <td>-0.476463</td>\n      <td>0.002107</td>\n      <td>3.640661</td>\n      <td>1954.083002</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>MO</th>\n      <td>8578.000000</td>\n      <td>23698.000000</td>\n      <td>12001.000000</td>\n      <td>0.929445</td>\n      <td>8578.000000</td>\n      <td>4334.000000</td>\n      <td>6992.000000</td>\n      <td>216.000000</td>\n      <td>27.000000</td>\n      <td>1343.000000</td>\n      <td>...</td>\n      <td>11503.000000</td>\n      <td>1.666028</td>\n      <td>20.000000</td>\n      <td>35.000000</td>\n      <td>0.000271</td>\n      <td>-0.536726</td>\n      <td>0.018431</td>\n      <td>4.093326</td>\n      <td>574.182598</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>IM</th>\n      <td>2959.000000</td>\n      <td>3553.000000</td>\n      <td>3288.000000</td>\n      <td>0.985907</td>\n      <td>2959.000000</td>\n      <td>376.000000</td>\n      <td>2879.000000</td>\n      <td>27.000000</td>\n      <td>7.000000</td>\n      <td>46.000000</td>\n      <td>...</td>\n      <td>530.000000</td>\n      <td>1.063869</td>\n      <td>6.000000</td>\n      <td>13.000000</td>\n      <td>0.000642</td>\n      <td>-0.734882</td>\n      <td>0.001026</td>\n      <td>4.291894</td>\n      <td>72.743141</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>SM</th>\n      <td>1169.000000</td>\n      <td>2288.000000</td>\n      <td>2183.000000</td>\n      <td>0.926570</td>\n      <td>1169.000000</td>\n      <td>1187.000000</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1142.000000</td>\n      <td>...</td>\n      <td>2259.000000</td>\n      <td>1.016949</td>\n      <td>2.000000</td>\n      <td>37.000000</td>\n      <td>0.000921</td>\n      <td>-0.339166</td>\n      <td>0.000000</td>\n      <td>2.996304</td>\n      <td>33.599915</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>AX</th>\n      <td>1418.000000</td>\n      <td>1927.000000</td>\n      <td>1718.000000</td>\n      <td>0.992490</td>\n      <td>1418.000000</td>\n      <td>313.000000</td>\n      <td>1324.000000</td>\n      <td>26.000000</td>\n      <td>28.000000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>455.000000</td>\n      <td>1.120489</td>\n      <td>5.000000</td>\n      <td>21.000000</td>\n      <td>0.001285</td>\n      <td>-0.501270</td>\n      <td>0.001380</td>\n      <td>3.384614</td>\n      <td>21.820762</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>CV</th>\n      <td>1873.000000</td>\n      <td>3663.000000</td>\n      <td>3643.000000</td>\n      <td>0.990753</td>\n      <td>1873.000000</td>\n      <td>1804.000000</td>\n      <td>54.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1816.000000</td>\n      <td>...</td>\n      <td>3605.000000</td>\n      <td>1.003843</td>\n      <td>2.000000</td>\n      <td>14.000000</td>\n      <td>0.000550</td>\n      <td>-0.318008</td>\n      <td>0.000002</td>\n      <td>3.149997</td>\n      <td>93.046447</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>108 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "countries = dict()\n",
    "for country, count in country_count.items():\n",
    "    country_dict = dict()\n",
    "    for column in analysis_df.columns:\n",
    "        country_dict[column] = 0\n",
    "    country_dict[\"count\"] = 0\n",
    "    countries[country] = country_dict\n",
    "for index, row in analysis_df.iterrows():\n",
    "    as_number = str(index)\n",
    "    if as_number not in geo_dict:\n",
    "        continue\n",
    "    country = geo_dict[as_number]\n",
    "    for column in analysis_df.columns:\n",
    "        countries[country][column] = countries[country][column] + row[column]\n",
    "    countries[country][\"count\"] = countries[country][\"count\"] + 1\n",
    "# average\n",
    "for country, row in countries.items():\n",
    "    for column, data in row.items():\n",
    "        if row[\"count\"] != 0 and column != \"count\":\n",
    "            countries[country][column] = data / row[\"count\"]\n",
    "\n",
    "country_df = pd.DataFrame.from_dict(countries, orient=\"index\").drop(columns=[\"avg_shortest_path_len\"])\n",
    "country_df = country_df.query(\"count != 0\")\n",
    "country_df"
   ]
  },
  {
   "source": [
    "## dataframe with analysis data, for LCC coverage study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcc_df = pd.read_csv(\"analysis_2020_08/analysis.tsv\", delimiter=\"\\t\", index_col=0)[[\"ds_nodes\",\"largest_cc_size\", \"largest_cc_coverage\"]]\n",
    "lcc_df_2 = pd.read_csv(\"analysis_2020_08_lcc/analysis.tsv\", delimiter=\"\\t\", index_col=0)\n",
    "lcc_df_whole = lcc_df_2.append(lcc_df)"
   ]
  },
  {
   "source": [
    "## choose a few countries and build a dataframe each"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BR = pd.DataFrame()\n",
    "df_CN = pd.DataFrame()\n",
    "df_DE = pd.DataFrame()\n",
    "df_FR = pd.DataFrame()\n",
    "df_IT = pd.DataFrame()\n",
    "df_JP = pd.DataFrame()\n",
    "df_RU = pd.DataFrame()\n",
    "df_US = pd.DataFrame()\n",
    "df_INTER = pd.DataFrame()\n",
    "for index, row in lcc_df_whole.iterrows():\n",
    "    as_number = str(index)\n",
    "    if as_number not in geo_dict:\n",
    "        pass\n",
    "    elif geo_dict[as_number] == \"BR\":\n",
    "        df_BR = df_BR.append(row)\n",
    "    elif geo_dict[as_number] == \"CN\":\n",
    "        df_CN = df_CN.append(row)\n",
    "    elif geo_dict[as_number] == \"DE\":\n",
    "        df_DE = df_DE.append(row)\n",
    "    elif geo_dict[as_number] == \"FR\":\n",
    "        df_FR = df_FR.append(row)\n",
    "    elif geo_dict[as_number] == \"IT\":\n",
    "        df_IT = df_IT.append(row)\n",
    "    elif geo_dict[as_number] == \"JP\":\n",
    "        df_JP = df_JP.append(row)\n",
    "    elif geo_dict[as_number] == \"RU\":\n",
    "        df_RU = df_RU.append(row)\n",
    "    elif geo_dict[as_number] == \"US\":\n",
    "        df_US = df_US.append(row)\n",
    "    elif geo_dict[as_number] == \"INTERNATIONAL\":\n",
    "        df_INTER = df_INTER.append(row)\n",
    "df_BR.index.name = \"as_number\"\n",
    "df_CN.index.name = \"as_number\"\n",
    "df_DE.index.name = \"as_number\"\n",
    "df_FR.index.name = \"as_number\"\n",
    "df_IT.index.name = \"as_number\"\n",
    "df_JP.index.name = \"as_number\"\n",
    "df_RU.index.name = \"as_number\"\n",
    "df_US.index.name = \"as_number\"\n",
    "df_INTER.index.name = \"as_number\"\n",
    "\n",
    "# save to csv\n",
    "with open(\"analysis_2020_08/lcc_BR.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_BR.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_CN.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_CN.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_DE.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_DE.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_FR.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_FR.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_IT.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_IT.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_JP.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_JP.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_RU.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_RU.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_US.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_US.to_csv(out_file)\n",
    "with open(\"analysis_2020_08/lcc_INTER.csv\", \"w\", encoding=\"utf8\") as out_file:\n",
    "    df_INTER.to_csv(out_file)"
   ]
  },
  {
   "source": [
    "## avg each country"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       ds_nodes  largest_cc_size  largest_cc_coverage  count\n",
       "CA  1112.370833      1552.127083             0.764373    480\n",
       "GB  2674.062500      3638.099085             0.813568    656\n",
       "HK  1539.268750      2453.662500             0.590035    160\n",
       "CO  6355.829787      5791.212766             0.615037     47\n",
       "US  2533.549163      3650.748745             0.762718   4780\n",
       "..          ...              ...                  ...    ...\n",
       "CU  4196.000000      3072.000000             0.560482      1\n",
       "MF    95.000000       108.000000             0.981818      1\n",
       "PM   114.000000       120.000000             0.380952      1\n",
       "NU    73.000000         2.000000             0.013699      1\n",
       "AI    31.500000        24.500000             0.717391      2\n",
       "\n",
       "[224 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds_nodes</th>\n      <th>largest_cc_size</th>\n      <th>largest_cc_coverage</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CA</th>\n      <td>1112.370833</td>\n      <td>1552.127083</td>\n      <td>0.764373</td>\n      <td>480</td>\n    </tr>\n    <tr>\n      <th>GB</th>\n      <td>2674.062500</td>\n      <td>3638.099085</td>\n      <td>0.813568</td>\n      <td>656</td>\n    </tr>\n    <tr>\n      <th>HK</th>\n      <td>1539.268750</td>\n      <td>2453.662500</td>\n      <td>0.590035</td>\n      <td>160</td>\n    </tr>\n    <tr>\n      <th>CO</th>\n      <td>6355.829787</td>\n      <td>5791.212766</td>\n      <td>0.615037</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>US</th>\n      <td>2533.549163</td>\n      <td>3650.748745</td>\n      <td>0.762718</td>\n      <td>4780</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>CU</th>\n      <td>4196.000000</td>\n      <td>3072.000000</td>\n      <td>0.560482</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>MF</th>\n      <td>95.000000</td>\n      <td>108.000000</td>\n      <td>0.981818</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>PM</th>\n      <td>114.000000</td>\n      <td>120.000000</td>\n      <td>0.380952</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>NU</th>\n      <td>73.000000</td>\n      <td>2.000000</td>\n      <td>0.013699</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>AI</th>\n      <td>31.500000</td>\n      <td>24.500000</td>\n      <td>0.717391</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>224 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "countries = dict()\n",
    "for country, count in country_count.items():\n",
    "    country_dict = dict()\n",
    "    for column in lcc_df_whole.columns:\n",
    "        country_dict[column] = 0\n",
    "    country_dict[\"count\"] = 0\n",
    "    countries[country] = country_dict\n",
    "for index, row in lcc_df_whole.iterrows():\n",
    "    as_number = str(index)\n",
    "    if as_number not in geo_dict:\n",
    "        continue\n",
    "    country = geo_dict[as_number]\n",
    "    for column in lcc_df_whole.columns:\n",
    "        countries[country][column] = countries[country][column] + row[column]\n",
    "    countries[country][\"count\"] = countries[country][\"count\"] + 1\n",
    "# average\n",
    "for country, row in countries.items():\n",
    "    for column, data in row.items():\n",
    "        if row[\"count\"] != 0 and column != \"count\":\n",
    "            countries[country][column] = data / row[\"count\"]\n",
    "\n",
    "country_df = pd.DataFrame.from_dict(countries, orient=\"index\")\n",
    "country_df = country_df.query(\"count != 0\")\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}